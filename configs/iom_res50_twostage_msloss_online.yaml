# general
samples_per_class: 4
classes_per_batch: 50
batch_size: 200
eval_batch_size: 200
input_size: 112
# embd_shape is for the Resnet, backbone
embd_shape: 512
#iom_res50_twostage_triplet -- only two stage with triplet loss
#iom_res50_twostage_triplet and quantization loss -- triplet loss + quantization loss, this in another config file
sub_name: 'iom_res50_twostage_msloss_online'
backbone_type: 'ResNet50' # 'ResNet50', 'MobileNetV2'
head_type: IoMHead # 'ArcHead', 'NormHead'
is_ccrop: False # central-cropping or not

# train /media/xingbo/Storage/facedata/vgg_mtcnnpy_160 ./data/split VGG png MS jpg
train_dataset: '/home/xingbo/facedata/ms1m_align_112/imgs'
#train_dataset: '/media/xingbo/Storage/facedata/vgg_mtcnnpy_160'
img_ext: 'jpg'
dataset_ext: 'ms'
# for metric learning, we have 1.  batch_hard_triplet 2. batch_all_triplet_loss 3. batch_all_arc_triplet_loss 4. semihard_triplet_loss
loss_fun: 'ms_loss'
triplet_margin: 0
binary_img: False
num_classes: 85742
# I generate 1 milion triplets
num_samples: 3000000
epochs: 30
base_lr: 0.001
w_decay: !!float 5e-4
save_steps: 5000
q: 8
# m, the projection length would be m x q
m: 256
# test
test_dataset: './data/test_dataset'
test_dataset_ytf: './data/test_dataset/aligned_images_DB_YTF/'
test_dataset_fs: './data/test_dataset/facescrub_images_112x112/'