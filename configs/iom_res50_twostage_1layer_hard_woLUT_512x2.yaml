# general
samples_per_class: 4
classes_per_batch: 60
batch_size: 240
eval_batch_size: 200
input_size: 112
# embd_shape is for the Resnet, backbone
embd_shape: 512
#iom_res50_twostage_triplet -- only two stage with triplet loss
#iom_res50_twostage_triplet and quantization loss -- triplet loss + quantization loss, this in another config file
sub_name: 'iom_res50_twostage_1layer_hard_woLUT_512x2'
backbone_type: 'ResNet50' # 'ResNet50', 'MobileNetV2'
head_type: IoMHead # 'ArcHead', 'NormHead'
is_ccrop: False # central-cropping or not
#tanh sigmoid
bin_lut_loss: 'none'

# train /media/xingbo/Storage/facedata/vgg_mtcnnpy_160 ./data/split /media/xingbo/Storage/facedata/ms1m_align_112/imgs
train_dataset: '/home/xingbo/facedata/ms1m_align_112/imgs'
#train_dataset: '/media/xingbo/Storage/facedata/vgg_mtcnnpy_160'
img_ext: 'jpg'
dataset_ext: 'ms'
# for metric learning, we have 1. triplet_semi batch_hard_triplet 2. batch_all_triplet_loss 3. batch_all_arc_triplet_loss
loss_fun: 'batch_hard_triplet'
triplet_margin: -1
binary_img: False
num_classes: 85742
# I generate 1 milion triplets
num_samples: 3000000
epochs: 50
base_lr: 0.001
w_decay: !!float 5e-4
save_steps: 10000
q: 2
# m, the projection length would be m x q
m: 512
# test
test_dataset: './data/test_dataset'
test_dataset_ytf: './data/test_dataset/aligned_images_DB_YTF/'
test_dataset_fs: './data/test_dataset/facescrub_images_112x112/'